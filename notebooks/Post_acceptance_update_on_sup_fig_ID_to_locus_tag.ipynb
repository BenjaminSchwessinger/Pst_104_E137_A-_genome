{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversion of ID identifiers to locus_tag identifiers in all supplemental files\n",
    "This notebooks converts all the supplemental files that contain IDs as gene/protein identifieres to supplemental files with locus_tag as identifiers. This is to adjust the supplemnetal files to the format of how gene and protein sequences are provide. In addition, using locus_tags will ease the comparison of this genomes with others.\n",
    "Files with the following "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-19T01:29:02.062569Z",
     "start_time": "2018-02-19T01:29:02.057055Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-19T01:25:52.425264Z",
     "start_time": "2018-02-19T01:25:51.596202Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input folder and output folder\n",
    "INPUT='../supplemental_files/'\n",
    "OUTPUT='../supplemental_files/ID_to_locus_tag'\n",
    "if not os.path.exists(OUTPUT):\n",
    "    os.mkdir(OUTPUT)\n",
    "GENOME_PATH = '../Assembly/'\n",
    "\n",
    "#input gff files\n",
    "P_GFF = pd.read_csv(os.path.join(GENOME_PATH, 'Pst_104E_v13_p_ctg.anno.gff3'), sep='\\t', header=None)\n",
    "H_GFF = pd.read_csv(os.path.join(GENOME_PATH, 'Pst_104E_v13_h_ctg.anno.gff3'), sep='\\t', header=None)\n",
    "\n",
    "#Supplemental files to change\n",
    "sups = ['_2', '_3', '_4', '_5', '_6', '_7','_8','_9', '_10', '_11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-19T01:43:08.389661Z",
     "start_time": "2018-02-19T01:43:08.339083Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getIdToLocusDict(p_gff=P_GFF, h_gff=H_GFF):\n",
    "    '''returns a dictionary with key: ID and val: locus_tag from a\n",
    "    DataFrame of haplotig and primary contig gff3 files containing\n",
    "    attribute entries (column 9) such as:\n",
    "    ID=evm.TU.pcontig_000.1;locus_tag=DK0911_00000;Name=EVM prediction pcontig_000.1'''\n",
    "    \n",
    "    p_gff_genes = p_gff.loc[(p_gff[2] == 'mRNA') | (p_gff[2] == 'gene')]\n",
    "    h_gff_genes = h_gff.loc[(h_gff[2] == 'mRNA') | (h_gff[2] == 'gene')]\n",
    "    \n",
    "    dSeries = pd.concat([h_gff_genes[8], p_gff_genes[8]], ignore_index=True)\n",
    "\n",
    "    idSearch = re.compile(r'ID=(.*?);')\n",
    "    locusSearch = re.compile(r'^.*locus_tag=(.*?)(;|$)')\n",
    "\n",
    "    d = {}\n",
    "\n",
    "    for attr in dSeries:\n",
    "        key = idSearch.match(attr).group(1)\n",
    "        val = locusSearch.match(attr).group(1)\n",
    "        if key in d.keys():\n",
    "            print('Unexpected: locus tag: %s is already in dictionary!' % key)\n",
    "        d[key] = val\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-19T01:43:08.710823Z",
     "start_time": "2018-02-19T01:43:08.700140Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mapWithDict(x, used_dict):\n",
    "    if x == 'NaN':\n",
    "        return x\n",
    "    if x in used_dict:\n",
    "        return used_dict[x]\n",
    "    print(\"x: %s\\n is not in the dictionary mapping loci to id.\" %x)\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-19T01:43:09.056186Z",
     "start_time": "2018-02-19T01:43:09.049610Z"
    }
   },
   "outputs": [],
   "source": [
    "files_to_change = [os.path.join(INPUT, x) for x in os.listdir(INPUT) if \\\n",
    "                   any([y in x for y in sups]) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-19T01:43:09.843866Z",
     "start_time": "2018-02-19T01:43:09.500120Z"
    }
   },
   "outputs": [],
   "source": [
    "id_To_loc_dict = getIdToLocusDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-19T02:03:21.802027Z",
     "start_time": "2018-02-19T02:03:19.971368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../supplemental_files/ID_to_locus_tag/Supplemental_file_11_id_to_locus_tag.txt\n",
      "../supplemental_files/ID_to_locus_tag/Supplemental_file_3_id_to_locus_tag.txt\n",
      "../supplemental_files/ID_to_locus_tag/Supplemental_file_2_id_to_locus_tag.txt\n",
      "../supplemental_files/ID_to_locus_tag/Supplemental_file_9_id_to_locus_tag.txt\n",
      "../supplemental_files/ID_to_locus_tag/Supplemental_file_8_id_to_locus_tag.txt\n",
      "../supplemental_files/ID_to_locus_tag/Supplemental_file_6_id_to_locus_tag.txt\n",
      "../supplemental_files/ID_to_locus_tag/Supplemental_file_5_id_to_locus_tag.txt\n",
      "../supplemental_files/ID_to_locus_tag/Supplemental_file_10_id_to_locus_tag.txt\n",
      "../supplemental_files/ID_to_locus_tag/Supplemental_file_7_id_to_locus_tag.txt\n",
      "../supplemental_files/ID_to_locus_tag/Supplemental_file_4_id_to_locus_tag.txt\n"
     ]
    }
   ],
   "source": [
    "idSearch = re.compile(r'(evm.\\S*)')\n",
    "for file in files_to_change:\n",
    "    out_name = file.split('/')[-1].split('.')[0]\n",
    "    out_name = '%s_id_to_locus_tag.txt' % os.path.join(OUTPUT, out_name)\n",
    "    print(out_name)\n",
    "    with open(file) as in_fh:\n",
    "        with open(out_name, 'w+') as out_fh:\n",
    "            for line in in_fh:\n",
    "                if 'evm'  in line:\n",
    "                    new_line = line.rstrip()\n",
    "                    match_list = idSearch.findall(line)\n",
    "                    for found in match_list:\n",
    "                        new_line = new_line.replace(found, id_To_loc_dict[found])\n",
    "                    print(new_line, file=out_fh)\n",
    "                else:\n",
    "                    new_line = line.rstrip()\n",
    "                    print(new_line, file=out_fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
