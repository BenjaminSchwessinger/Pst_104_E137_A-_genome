{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is aimed at doing allelic comparison between primary contigs and hapltotigs. This was used to generated dataframes used during the analysis and evolved during the analysis. So it might be a bit more complicated as it needed to be but it worked.\n",
    "\n",
    "\n",
    "This notebook was only designed for the purpose of analyzing the Pst-104E genome. No gurantees it works in any other situtation. It will have spelling errors due to the lack of autocorrection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This juypter notebook is tartgeted towards defining alleles "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook defines alleles based on a Falcon-Unzip assembly where relational information between two contigs are available.\n",
    "\n",
    "#### The input as follows:\n",
    "* Assembletics alingment of all haplotigs onto their corresponding primary contigs. The *.oriented_coords.csv will be converted to a gff file of haplotig alingments onto their respective primary contigs\n",
    "* gff file of all features. This will be filtered down to genes only and separated out for each contig\n",
    "* protein and gene fa files for reciprocal blast of haplotig sequences onto primary sequences\n",
    "\n",
    "#### What happens:\n",
    "* for each primary gene/protein the the overlapping haplotig is pulled out and added to the blast dataframe\n",
    "* this blast dataframe of primary proteins onto haplotig proteins is than used for filtering to provide the following files\n",
    "* best blast hits are first filtered on e-value minimums followed by BitScore maximum\n",
    "\n",
    "#### What comes out in the alleles folder:\n",
    "##### for primary genes/proteins\n",
    "* a set of files that contain two proteins IDs identifying the two alleles.  \n",
    "* *_p_ctg.h_contig_overlap.alleles contains best blast hits of the primary protein on haplotig proteins of the overlapping haplotig (truely linked alleles).\n",
    "* *_p_ctg.no_respective_h_contig_overlap.alleles contains all primary protein that don't have a blast hit on the overlapping haplotig but another haplotig associated with its primary contig.\n",
    "* *_p_ctg.no_specific_h_contig_overlap.alleles contains all primary proteins that don't have a blast hit on an associated haplotig but another haplotig.\n",
    "* *_p_ctg.no_alleles contains all primary proteins without blast hit on haplotigs.\n",
    "\n",
    "##### for haplotig genes/proteins\n",
    "* *_h_ctg.no.alleles contains all haplotig proteins that are not associated with a primary allele in the above analysis.\n",
    "* *_h_ctg.no.best_p_hits.alleles contains all haplotig proteins that are not associated with a primary allele in the above analysis but have a blast hit non-withstanding. This might be duplications in the haplotigs.\n",
    "* *_h_ctg.no.no_p_hits.alleles contains all haplotig proteins that have no blast hit.\n",
    "\n",
    "##### filtering of blast output\n",
    "* filtering of blast output is possible on Query coverage of the blast hit [Qcov] and the percentage identity of the aligenment [PctID]. This generates additional outfiles with *.QcovXX.PctIDYY.alleles. The default values are set to Qcov80 and PctID70.\n",
    "\n",
    "#### What else to consider:\n",
    "* the script was tested for outputing the right number of protein sequences for primary and haplotig sequences.\n",
    "* this is a script and not a program. No warrenties.\n",
    "* Feedback always welcome.\n",
    "* Path and other variables are defined at the top of the script.\n",
    "* It assumes that primary contig sequences are labled as e.g. pcontig_000 and associated haplotigs as hcontig_000_0xx.\n",
    "\n",
    "#### Downstream considerations:\n",
    "* Why have some proteins no blast hits? Is it simple that their gene models are missing? Seen this and working on this.\n",
    "* In case of primary genes without blast hits do those lie in homozygous coverage areas? Working on this.\n",
    "* Are some of the h genes/proteins without alleles but with blast hits duplications that diverget?\n",
    "* Do some of the primary proteins/genes without blast hit on haplotigs have a good blast hit on other primary contigs? Is this reciprocal?\n",
    "* Can we use some of this information to talk about linkage of contigs or does this go to far without fully phased genomes using loooong reads or single nucleii sequencing? Would say yes so far.\n",
    "* Some primary proteins have two equal got hits are those duplications in the haplotig?\n",
    "* If we perform downstream genetic variation analysis between alleles do we see any GO, KEGG, effector or other functional domains enriched?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This second version of this allele analysis take the proteinortho5.pl input as reference for syntany analysis.\n",
    "\n",
    "This was run as follows:\n",
    "\n",
    "proteinortho5.pl -project=ph_ctg  -synteny ph_ctg/Pst_104E_v12_h_ctg_protein.faa ph_ctg/Pst_104E_v12_p_ctg_protein.faa\n",
    "\n",
    "<- this gave different results in the graph and regular file in verison 5.15.\n",
    "\n",
    "run the latest version with \n",
    "\n",
    "perl ~/anaconda3/envs/funannotate/proteinortho_v5.16/proteinortho5.pl -cpus=20 -project=ph_ctg_516  -synteny ph_ctg/Pst_104E_v12_h_ctg_protein.faa ph_ctg/Pst_104E_v12_p_ctg_protein.faa\n",
    "\n",
    "Use the poff-graph and poff-proteinortho-graph as bases for analysis\n",
    "\n",
    "Depending on this run the poff_header needs to be defined. In current case 'Target' followed 'Query'\n",
    "\n",
    "#### The additional input required\n",
    "* is the .poff from proteinortho. This will be used for filtering as all alleles need have a True in the PO_allele column to be included in the output. All other filtering is done as described above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from Bio import SeqIO\n",
    "import pysam\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from pybedtools import BedTool\n",
    "import numpy as np\n",
    "import pybedtools\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import subprocess\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define the PATH\n",
    "BASE_AA_PATH = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12'\n",
    "BASE_A_PATH = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/032017_assembly'\n",
    "ASSEMBLETICS_INPATH = os.path.join(BASE_AA_PATH, 'Assembletics')\n",
    "BLAST_DB = os.path.join(BASE_AA_PATH, 'blast_DB')\n",
    "OUT_PATH = os.path.join(BASE_AA_PATH, 'allele_analysis')\n",
    "OUT_tmp = os.path.join(OUT_PATH, 'tmp')\n",
    "PROTEINORTHO = os.path.join(BASE_AA_PATH, 'proteinortho')\n",
    "#renamed the allele path to reflect the proteinortho results\n",
    "ALLELE_PATH = os.path.join(OUT_PATH, 'alleles_proteinortho_graph516')\n",
    "if not os.path.isdir(OUT_PATH):\n",
    "    os.mkdir(OUT_PATH)\n",
    "if not os.path.isdir(OUT_tmp):\n",
    "    os.mkdir(OUT_tmp)\n",
    "if not os.path.exists(ALLELE_PATH):\n",
    "    os.mkdir(ALLELE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define your p and h genome and move it into the allele analysis folder\n",
    "p_genome = 'Pst_104E_v12_p_ctg'\n",
    "h_genome = 'Pst_104E_v12_h_ctg'\n",
    "genome_file_suffix = '.genome_file'\n",
    "for x in (x + '.fa' for x in [p_genome, h_genome]):\n",
    "    shutil.copy2(BASE_A_PATH+'/'+x, OUT_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get protetinortho syntany file which ends with .poff\n",
    "poff_graph_fn = os.path.join(PROTEINORTHO, 'ph_ctg_516.poff-graph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define ENV parameters for blast hits and threads used in blast analysis\n",
    "n_threads = 16\n",
    "e_value = 1e-3\n",
    "Qcov_cut_off = 80 #this defines the mimimum coverage of the Query to be required for filtering. Will become part of name.\n",
    "PctID_cut_off = 70 #this defines the mimimum PctID accross the alignment to be required for filtering. Will become part of name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def att_column_p(x, y, z, a, b):\n",
    "    '''Generate attribute column of h on p p_gff dataframe.\n",
    "    '''\n",
    "    string = 'h_contig=%s;query_start=%s;query_stop=%s;query_length=%s;query_aln_ln=%s' % (x, str(y), str(z), str(a), str(b))\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def att_column_h(x, y, z, a, b):\n",
    "    '''Generate attribute column of h on p h_gff dataframe.\n",
    "    '''\n",
    "    string = 'p_contig=%s;ref_start=%s;ref_stop=%s;ref_length=%s;ref_aln_ln=%s' % (x, str(y), str(z), str(a), str(b))\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gene_contig_subset(df, contig, feature):\n",
    "    '''Input the gff and subset the feature columne by gene.\n",
    "        Return data frame subset by contig and gene'''\n",
    "    tmp_df = df[(df[0].str.contains(contig)) & (df[2]==feature)]\n",
    "    tmp_df.sort_values(3,inplace=True)\n",
    "    tmp_df.reset_index(drop=True, inplace=True)\n",
    "    return tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def same_contig_blast(x,y):\n",
    "    '''Function that checks if the blast hit in columne y is on the same contig as the the query sequence in\n",
    "    column y.\n",
    "    '''\n",
    "    q_contig = re.search(r'[p|h]([a-z]*_[0-9]*)_?', x).group(1)\n",
    "    if y != 'NaN':\n",
    "        hit_contig = re.search(r'[p|h]([a-z]*_[0-9]*)_?', y).group(1)\n",
    "    else:\n",
    "        hit_contig = 'NaN'\n",
    "    if q_contig == hit_contig:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def target_on_maped_haplotig(t_contig, h_contig_overlap):\n",
    "    '''Simple function that checks if the target contig is in the list of h overlaping contigs'''\n",
    "    if t_contig == False or h_contig_overlap == False:\n",
    "        return False  \n",
    "    else:\n",
    "        if t_contig in h_contig_overlap:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Considerations for blast analysis\n",
    "Do gene blast and protein blast. Initially go off protein blast results. They should be more imformative as it also includes the coding region and the frame.\n",
    "> Pull this in as a dataframe and filter it down as well to each contig. Do blasts both ways as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All databases generated and ready to go!\n"
     ]
    }
   ],
   "source": [
    "#generate the blast databases if not already present\n",
    "os.chdir(BLAST_DB)\n",
    "blast_dir_content = os.listdir(BLAST_DB)\n",
    "for x in blast_dir_content:\n",
    "    if x.endswith('.fa') and ({os.path.isfile(x + e) for e in ['.psq', '.phr', '.pin'] } != {True}\\\n",
    "           and {os.path.isfile(x + e) for e in ['.nin', '.nhr', '.nsq'] } != {True} ):\n",
    "\n",
    "        make_DB_options = ['-in']\n",
    "        make_DB_options.append(x)\n",
    "        make_DB_options.append('-dbtype')\n",
    "        if 'protein' in x:\n",
    "            make_DB_options.append('prot')\n",
    "        else:\n",
    "            make_DB_options.append('nucl')\n",
    "        make_DB_command = 'makeblastdb %s' % ' '.join(make_DB_options)\n",
    "        make_DB_stderr = subprocess.check_output(make_DB_command, shell=True, stderr=subprocess.STDOUT)\n",
    "        print('%s is done!' % make_DB_command)\n",
    "print(\"All databases generated and ready to go!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blastp -query Pst_104E_v12_p_ctg.anno.protein.fa -db Pst_104E_v12_h_ctg.anno.protein.fa -outfmt 6 -evalue 0.001 -num_threads 16 > /home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/allele_analysis/Pst_104E_v12_p_ctg.Pst_104E_v12_h_ctg.0.001.blastp.outfmt6\n",
      "Previously done already!\n",
      "blastp -query Pst_104E_v12_h_ctg.anno.protein.fa -db Pst_104E_v12_p_ctg.anno.protein.fa -outfmt 6 -evalue 0.001 -num_threads 16 > /home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/allele_analysis/Pst_104E_v12_h_ctg.Pst_104E_v12_p_ctg.0.001.blastp.outfmt6\n",
      "Previously done already!\n",
      "blastn -query Pst_104E_v12_p_ctg.anno.gene.fa -db Pst_104E_v12_h_ctg.anno.gene.fa -outfmt 6 -evalue 0.001 -num_threads 16 > /home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/allele_analysis/Pst_104E_v12_p_ctg.Pst_104E_v12_h_ctg.0.001.blastn.outfmt6\n",
      "Previously done already!\n",
      "blastn -query Pst_104E_v12_h_ctg.anno.gene.fa -db Pst_104E_v12_p_ctg.anno.gene.fa -outfmt 6 -evalue 0.001 -num_threads 16 > /home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/allele_analysis/Pst_104E_v12_h_ctg.Pst_104E_v12_p_ctg.0.001.blastn.outfmt6\n",
      "Previously done already!\n"
     ]
    }
   ],
   "source": [
    "blast_dict = {}\n",
    "blast_dict['gene_fa'] = [x for x  in os.listdir(BLAST_DB) if x.endswith('gene.fa') and 'ph_ctg' not in x]\n",
    "blast_dict['protein_fa'] = [x for x  in os.listdir(BLAST_DB) if x.endswith('protein.fa') and 'ph_ctg' not in x]\n",
    "blast_stderr_dict = {}\n",
    "for key in blast_dict.keys():\n",
    "    for n, query in enumerate(blast_dict[key]):\n",
    "        tmp_list = blast_dict[key][:]\n",
    "        tmp_stderr_list = []\n",
    "        #this loops through all remaining files and does blast against all those\n",
    "        del tmp_list[n]\n",
    "        for db in tmp_list:\n",
    "            blast_options = ['-query']\n",
    "            blast_options.append(query)\n",
    "            blast_options.append('-db')\n",
    "\n",
    "\n",
    "            blast_options.append(db)\n",
    "            blast_options.append('-outfmt 6')\n",
    "            blast_options.append('-evalue')\n",
    "            blast_options.append(str(e_value))\n",
    "            blast_options.append('-num_threads')\n",
    "            blast_options.append(str(n_threads))\n",
    "            blast_options.append('>')\n",
    "            if 'gene' in query and 'gene' in db:\n",
    "                out_name_list = [ query.split('.')[0], db.split('.')[0], str(e_value), 'blastn.outfmt6']\n",
    "                out_name = os.path.join(OUT_PATH,'.'.join(out_name_list))\n",
    "                blast_options.append(out_name)\n",
    "                blast_command = 'blastn %s' % ' '.join(blast_options)\n",
    "            elif 'protein' in query and 'protein' in db:\n",
    "                out_name_list = [ query.split('.')[0], db.split('.')[0], str(e_value), 'blastp.outfmt6']\n",
    "                out_name = os.path.join(OUT_PATH,'.'.join(out_name_list))\n",
    "                blast_options.append(out_name)\n",
    "                blast_command = 'blastp %s' % ' '.join(blast_options)\n",
    "            print(blast_command)\n",
    "            if not os.path.exists(out_name):\n",
    "                blast_stderr_dict[blast_command] = subprocess.check_output(blast_command, shell=True, stderr=subprocess.STDOUT)\n",
    "                print(\"New blast run and done!\")\n",
    "            else:\n",
    "                blast_stderr_dict[blast_command] = 'Previously done already!'\n",
    "                print('Previously done already!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make a sequnece length dict for all genes and proteins for which blast was performed\n",
    "seq_list = []\n",
    "length_list =[]\n",
    "for key in blast_dict.keys():\n",
    "    for file in blast_dict[key]:\n",
    "        for seq in SeqIO.parse(open(file), 'fasta'):\n",
    "            seq_list.append(seq.id)\n",
    "            length_list.append(len(seq.seq))\n",
    "length_dict = dict(zip(seq_list, length_list))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get assembletics folders\n",
    "ass_folders = [os.path.join(ASSEMBLETICS_INPATH, x) for x in os.listdir(ASSEMBLETICS_INPATH) if x.endswith('_php_8kbp')]\n",
    "ass_folders.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read in the gff files\n",
    "p_gff = pd.read_csv(BASE_A_PATH+'/'+p_genome+'.anno.gff3', sep='\\t', header=None)\n",
    "h_gff = pd.read_csv(BASE_A_PATH+'/'+h_genome+'.anno.gff3', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:33: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:34: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n"
     ]
    }
   ],
   "source": [
    "#read in the blast df and add QLgth and QCov columns\n",
    "blast_out_dict = {}\n",
    "blast_header = ['Query', 'Target', 'PctID', 'AlnLgth', 'NumMis', 'NumGap', 'StartQuery', 'StopQuery', 'StartTarget',\\\n",
    "              'StopTarget', 'e-value','BitScore']\n",
    "for key in blast_stderr_dict.keys():\n",
    "    file = key.split('>')[-1][1:]\n",
    "    tmp_key = file.split('/')[-1]\n",
    "    tmp_df = pd.read_csv(file, sep='\\t', header=None, names=blast_header)\n",
    "    tmp_df[\"QLgth\"] = tmp_df[\"Query\"].apply(lambda x: length_dict[x])\n",
    "    tmp_df[\"QCov\"] = tmp_df['AlnLgth']/tmp_df['QLgth']*100\n",
    "    tmp_df.sort_values(by=['Query', 'e-value','BitScore', ],ascending=[True, True, False], inplace=True)\n",
    "    #now make sure to add proteins/genes without blast hit to the dataframes\n",
    "    #check if gene blast or protein blast and pull out respective query file\n",
    "    if file.split('.')[-2] == 'blastp':\n",
    "        tmp_blast_seq = [x for x in blast_dict['protein_fa'] if x.startswith(tmp_key.split('.')[0])][0]\n",
    "    elif file.split('.')[-2] == 'blastn':\n",
    "        tmp_blast_seq = [x for x in blast_dict['gene_fa'] if x.startswith(tmp_key.split('.')[0])][0]\n",
    "    tmp_all_blast_seq = []\n",
    "    #make list off all query sequences\n",
    "    for seq in SeqIO.parse(os.path.join(BLAST_DB, tmp_blast_seq), 'fasta'):\n",
    "        tmp_all_blast_seq.append(str(seq.id))\n",
    "    tmp_all_queries_w_hit = tmp_df[\"Query\"].unique()\n",
    "    tmp_queries_no_hit = set(tmp_all_blast_seq) - set(tmp_all_queries_w_hit)\n",
    "    no_hit_list = []\n",
    "    #loop over the quieres with no hit and make list of list out of them the first element being the query id\n",
    "    for x in tmp_queries_no_hit:\n",
    "        NA_list = ['NaN'] * len(tmp_df.columns)\n",
    "        NA_list[0] = x\n",
    "        no_hit_list.append(NA_list)\n",
    "    tmp_no_hit_df = pd.DataFrame(no_hit_list)\n",
    "    tmp_no_hit_df.columns = tmp_df.columns\n",
    "    tmp_no_hit_df['QLgth'] = tmp_no_hit_df.Query.apply(lambda x: length_dict[x])\n",
    "    tmp_df = tmp_df.append(tmp_no_hit_df)\n",
    "    tmp_df['q_contig'] = tmp_df['Query'].str.extract(r'([p|h][a-z]*_[^.]*).?')\n",
    "    tmp_df['t_contig'] = tmp_df['Target'].str.extract(r'([p|h][a-z]*_[^.]*).?')\n",
    "    #fix that if you don't extract anything return False and not 'nan'\n",
    "    tmp_df['t_contig'].fillna(False, inplace=True)\n",
    "    tmp_df['q_contig == t_contig'] = tmp_df.apply(lambda row: same_contig_blast(row['Query'], row['Target']), axis =1)\n",
    "    tmp_df.reset_index(inplace=True, drop=True)\n",
    "    blast_out_dict[tmp_key] = tmp_df.iloc[:,:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check on /home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/Assembletics/Pst_104E_v12_pcontig_118_php_8kbp assembletics\n",
      "Check on /home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/Assembletics/Pst_104E_v12_pcontig_193_php_8kbp assembletics\n"
     ]
    }
   ],
   "source": [
    "for folder in ass_folders:\n",
    "    '''\n",
    "    From oriented_coords.csv files generate gff files with the following set up.\n",
    "    h_contig overlap\n",
    "    'query', 'ref', 'h_feature', 'query_start', 'query_end', 'query_aln_len', 'strand', 'frame', 'attribute_h'\n",
    "    p_contig overlap\n",
    "    'ref', 'query', 'p_feature','ref_start','ref_end', 'alignment_length', 'strand', 'frame', 'attribute_p'.\n",
    "    Save those file in a new folder for further downstream analysis. The same folder should include the contig and gene filtered\n",
    "    gffs. \n",
    "    '''\n",
    "    orient_coords_file = [os.path.join(folder, x) for x in os.listdir(folder) if x.endswith('oriented_coords.csv')][0]\n",
    "    #load in df and generate several additions columns\n",
    "    tmp_df = pd.read_csv(orient_coords_file, sep=',')\n",
    "    #check if there is any resonable alignment if not go to the next one\n",
    "    if len(tmp_df) == 0:\n",
    "        print('Check on %s assembletics' % (folder))\n",
    "        continue\n",
    "    tmp_df['p_feature'] = \"haplotig\"\n",
    "    tmp_df['h_feature'] ='primary_contig'\n",
    "    tmp_df['strand'] = \"+\"\n",
    "    tmp_df['frame'] = 0\n",
    "    tmp_df['query_aln_len'] = abs(tmp_df['query_end']-tmp_df['query_start'])\n",
    "    tmp_df['alignment_length'] = abs(tmp_df['ref_end'] - tmp_df['ref_start'])\n",
    "    tmp_df.reset_index(drop=True, inplace=True)\n",
    "    tmp_df.sort_values('query', inplace=True)\n",
    "    tmp_df['attribute_p'] = tmp_df.apply(lambda row: att_column_p(row['query'],row['query_start'], row['query_end'],\\\n",
    "                                                         row['query_length'], row['query_aln_len']), axis=1)\n",
    "    \n",
    "    tmp_df['attribute_h'] = tmp_df.apply(lambda row: att_column_h(row['ref'], row['ref_start'], row['ref_end'],\\\n",
    "                                                                  row['ref_length'], row['alignment_length']), axis=1)\n",
    "    \n",
    "    #generate tmp gff dataframe\n",
    "    tmp_p_gff_df = tmp_df.loc[:, ['ref', 'query', 'p_feature','ref_start','ref_end', 'alignment_length', 'strand', 'frame', 'attribute_p']]\n",
    "    #now filter added if start < stop swap round. And if start == 0. This was mostly?! only? the case for haplotigs\n",
    "    tmp_p_gff_df['comp'] = tmp_p_gff_df['ref_start'] - tmp_p_gff_df['ref_end']\n",
    "    tmp_swap_index  = tmp_p_gff_df['comp'] > 0\n",
    "    tmp_p_gff_df.loc[tmp_swap_index, 'ref_start'] , tmp_p_gff_df.loc[tmp_swap_index, 'ref_end'] = tmp_p_gff_df['ref_end'], tmp_p_gff_df['ref_start']\n",
    "    #and if 'ref_start' == g\n",
    "    is_null_index  = tmp_p_gff_df['ref_start'] == 0\n",
    "    tmp_p_gff_df.loc[is_null_index, 'ref_start'] = 1\n",
    "    tmp_p_gff_df = tmp_p_gff_df.iloc[:, 0:9]\n",
    "    tmp_p_gff_df.sort_values('ref_start',inplace=True)\n",
    "    tmp_h_gff_df = tmp_df.loc[:, ['query', 'ref', 'h_feature', 'query_start', 'query_end', 'query_aln_len', 'strand', 'frame', 'attribute_h']]\n",
    "    #same fix for tmp_h_gff\n",
    "    tmp_h_gff_df['comp'] = tmp_h_gff_df['query_start'] - tmp_h_gff_df['query_end']\n",
    "    tmp_swap_index  = tmp_h_gff_df['comp'] > 0\n",
    "    tmp_h_gff_df.loc[tmp_swap_index, 'query_start'] , tmp_h_gff_df.loc[tmp_swap_index, 'query_end'] = tmp_h_gff_df['query_end'], tmp_h_gff_df['query_start']\n",
    "    #and if 'query_start' == g\n",
    "    is_null_index  = tmp_h_gff_df['query_start'] == 0\n",
    "    tmp_h_gff_df.loc[is_null_index, 'query_start'] = 1\n",
    "    tmp_h_gff_df = tmp_h_gff_df.iloc[:, 0:9]\n",
    "    tmp_h_gff_df.sort_values('query_start', inplace=True)\n",
    "    #make the outfolder and save gff files of overlap and filtered gene files\n",
    "    folder_suffix = folder.split('/')[-1]\n",
    "    #get the contig\n",
    "    contig = re.search(r'p([a-z]*_[0-9]*)_', folder_suffix).group(1)\n",
    "    out_folder = os.path.join(OUT_PATH, folder_suffix)\n",
    "    if not os.path.exists(out_folder):\n",
    "        os.mkdir(out_folder)\n",
    "    out_name_p = os.path.join(out_folder, folder_suffix )\n",
    "    tmp_p_gff_df.to_csv(out_name_p+'.p_by_h_cov.gff', sep='\\t' ,header=None, index =None)\n",
    "    out_name_h =  os.path.join(out_folder, folder_suffix)\n",
    "    tmp_h_gff_df.to_csv(out_name_h+'.h_by_p_cov.gff' , sep='\\t' ,header=None, index =None)\n",
    "    #write those out to new folder for php together with the p and h gff of genes\n",
    "    p_gene_gff = gene_contig_subset(p_gff, contig, 'gene')\n",
    "    p_gene_gff.to_csv(out_name_p+'.p_gene.gff', sep='\\t' ,header=None, index =None)\n",
    "    h_gene_gff = gene_contig_subset(h_gff, contig, 'gene')\n",
    "    h_gene_gff.to_csv(out_name_h+'.h_gene.gff', sep='\\t' ,header=None, index =None)\n",
    "    \n",
    "    #next would be to do overlap between the gene gff and the corresponding alingment gff. Write this out. Dict for each gene and its corresponding h_contig/p_contig\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now loop over the outfolders\n",
    "out_folders = [os.path.join(OUT_PATH, x) for x in os.listdir(OUT_PATH) if x.endswith('_php_8kbp')]\n",
    "out_folders.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the lenght of the intersect 588\n",
      "This is the lenght of the intersect 548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the lenght of the intersect 496\n",
      "This is the lenght of the intersect 417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the lenght of the intersect 319\n",
      "This is the lenght of the intersect 352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the lenght of the intersect 388\n",
      "This is the lenght of the intersect 308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the lenght of the intersect 266\n",
      "This is the lenght of the intersect 278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the lenght of the intersect 255\n",
      "This is the lenght of the intersect 335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the lenght of the intersect 299\n",
      "This is the lenght of the intersect 282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the lenght of the intersect 213\n",
      "This is the lenght of the intersect 226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the lenght of the intersect 276\n",
      "This is the lenght of the intersect 262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the lenght of the intersect 294\n",
      "This is the lenght of the intersect 289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the lenght of the intersect 253\n",
      "This is the lenght of the intersect 206\n",
      "This is the lenght of the intersect 240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the lenght of the intersect 116\n",
      "This is the lenght of the intersect 240\n",
      "This is the lenght of the intersect 174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the lenght of the intersect 196\n",
      "This is the lenght of the intersect 227\n",
      "This is the lenght of the intersect 181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the lenght of the intersect 164\n",
      "This is the lenght of the intersect 7\n",
      "This is the lenght of the intersect 155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the lenght of the intersect 186\n",
      "This is the lenght of the intersect 133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the lenght of the intersect 191\n",
      "This is the lenght of the intersect 153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the lenght of the intersect 152\n",
      "This is the lenght of the intersect 136\n",
      "This is the lenght of the intersect 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the lenght of the intersect 165\n",
      "This is the lenght of the intersect 111\n",
      "This is the lenght of the intersect 156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the lenght of the intersect 85\n",
      "This is the lenght of the intersect 95\n",
      "This is the lenght of the intersect 140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the lenght of the intersect 126\n",
      "This is the lenght of the intersect 69\n",
      "This is the lenght of the intersect 112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the lenght of the intersect 157\n",
      "This is the lenght of the intersect 108\n",
      "This is the lenght of the intersect 131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the lenght of the intersect 95\n",
      "This is the lenght of the intersect 136\n",
      "This is the lenght of the intersect 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the lenght of the intersect 104\n",
      "This is the lenght of the intersect 55\n",
      "This is the lenght of the intersect 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the lenght of the intersect 92\n",
      "This is the lenght of the intersect 94\n",
      "This is the lenght of the intersect 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the lenght of the intersect 61\n",
      "This is the lenght of the intersect 4\n",
      "This is the lenght of the intersect 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the lenght of the intersect 97\n",
      "This is the lenght of the intersect 31\n",
      "This is the lenght of the intersect 13\n",
      "This is the lenght of the intersect 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the lenght of the intersect 9\n",
      "This is the lenght of the intersect 33\n",
      "This is the lenght of the intersect 18\n",
      "This is the lenght of the intersect 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the lenght of the intersect 16\n",
      "This is the lenght of the intersect 64\n",
      "This is the lenght of the intersect 36\n",
      "This is the lenght of the intersect 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the lenght of the intersect 37\n",
      "This is the lenght of the intersect 37\n",
      "This is the lenght of the intersect 31\n",
      "This is the lenght of the intersect 11\n",
      "This is the lenght of the intersect 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the lenght of the intersect 20\n",
      "This is the lenght of the intersect 21\n",
      "This is the lenght of the intersect 20\n",
      "This is the lenght of the intersect 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the lenght of the intersect 6\n",
      "This is the lenght of the intersect 7\n",
      "This is the lenght of the intersect 17\n",
      "This is the lenght of the intersect 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the lenght of the intersect 1\n",
      "This is the lenght of the intersect 12\n",
      "This is the lenght of the intersect 7\n",
      "This is the lenght of the intersect 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the lenght of the intersect 0\n",
      "This is the lenght of the intersect 5\n",
      "This is the lenght of the intersect 0\n",
      "This is the lenght of the intersect 6\n",
      "This is the lenght of the intersect 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pybedtools/bedtool.py:3287: UserWarning: Default names for filetype gff are:\n",
      "['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes']\n",
      "but file has 18 fields; you can supply custom names with the `names` kwarg\n",
      "  % (self.file_type, _names, self.field_count()))\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "p_gene_h_contig_overlap_dict = {}\n",
    "for out_folder in out_folders:\n",
    "    tmp_folder_content = os.listdir(out_folder)\n",
    "    tmp_p_gene_gff = [os.path.join(out_folder, x) for x in tmp_folder_content if x.endswith('p_gene.gff') ][0]\n",
    "    tmp_p_gene_bed = pybedtools.BedTool(tmp_p_gene_gff).remove_invalid().saveas()\n",
    "    tmp_p_by_h_gff = [os.path.join(out_folder, x) for x in tmp_folder_content if x.endswith('p_by_h_cov.gff') ][0]\n",
    "    tmp_p_by_h_bed = pybedtools.BedTool(tmp_p_by_h_gff).remove_invalid().saveas()\n",
    "    #generate a bed intersect\n",
    "    p_gene_and_p_by_h = tmp_p_gene_bed.intersect(tmp_p_by_h_bed, wb=True)\n",
    "    #check the length of the obtained intersect is \n",
    "    print(\"This is the lenght of the intersect %i\" %len(p_gene_and_p_by_h ))\n",
    "    if len(p_gene_and_p_by_h) == 0:\n",
    "        continue\n",
    "    #turn this into a dataframe \n",
    "    p_gene_and_p_by_h_df = p_gene_and_p_by_h.to_dataframe()\n",
    "    p_gene_and_p_by_h_df['p_gene'] = p_gene_and_p_by_h_df[8].str.extract(r'ID=([^;]*);')\n",
    "    p_gene_and_p_by_h_df['p_protein'] = p_gene_and_p_by_h_df['p_gene'].str.replace('TU', 'model')\n",
    "    #safe this in the same folder as dataframe\n",
    "    p_gene_and_p_by_h_df.to_csv(tmp_p_gene_gff.replace('p_gene.gff', 'gene_haplotig_intersect.df'), sep='\\t', index=None)\n",
    "    p_gene_and_p_by_h_df_2 = p_gene_and_p_by_h_df.loc[:, [10, 'p_protein']]\n",
    "    #make a dict for the overlap of each gene with it's correspoding haplotig\n",
    "    tmp_p_gene_h_overlap_df = p_gene_and_p_by_h_df_2.groupby('p_protein')[10].apply(list)\n",
    "    tmp_p_gene_h_overlap_dict = dict(zip(tmp_p_gene_h_overlap_df.index, tmp_p_gene_h_overlap_df.values))\n",
    "    p_gene_h_contig_overlap_dict.update(tmp_p_gene_h_overlap_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get out the p_protein on h_protein blast out dataframe and appand the h_contig overlap for each protein\n",
    "_key = [x for x in blast_out_dict.keys() if x.startswith(p_genome) and x.split('.')[-2] == 'blastp' and x.endswith('outfmt6')][0]\n",
    "p_gene_h_contig_overlap_df = pd.DataFrame([p_gene_h_contig_overlap_dict.keys(), p_gene_h_contig_overlap_dict.values()],  index = ['p_protein', 'h_contig_overlap']).T\n",
    "_tmp_df = blast_out_dict[_key]\n",
    "_tmp_df = _tmp_df.merge(p_gene_h_contig_overlap_df, how='outer' ,left_on='Query', right_on='p_protein')\n",
    "_tmp_df['h_contig_overlap'].fillna(False, inplace=True)\n",
    "#check if the protein hit resites on the overlapping haplotig\n",
    "_tmp_df['t_contig == h_contig_overlap'] = _tmp_df.apply(lambda row: target_on_maped_haplotig(row['t_contig'], row['h_contig_overlap']), axis =1 )\n",
    "#blast_out_dict[_key] = _tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write the dataframe again\n",
    "_tmp_df.to_csv(os.path.join(OUT_PATH, _key+'.allele_analysis'), index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now mangale the data a bit\n",
    "#write out t_contig == h_contig_overlap best hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Qcov_cut_off = ''\n",
    "#PctID_cut_off = ''\n",
    "if Qcov_cut_off and PctID_cut_off:\n",
    "    pass\n",
    "else: \n",
    "    print('No cut off defined! Do you want to define it. Please go ahead above.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now pull in the proteinortho_df for allele analysis\n",
    "#this will add a new column to the dataframe called PO_allele which will be True when protein_ortho\n",
    "#says it is \n",
    "#co-orthologs will be filtered based on same contig, and e-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poff_graph_header = ['Target', 'Query', 'evalue_ab', 'bitscore_ab', 'evalue_ba', 'bitscore_ba', 'same_strand' , 'simscore']\n",
    "po_df = pd.read_csv(poff_graph_fn, sep='\\t', header=None, names=poff_graph_header, comment='#' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filter out the co-orthologs\n",
    "#co_po_df = po_df[po_df.Target.str.contains(',')].loc[:, ['Target', 'Query']].copy()\n",
    "#po_df = po_df[~po_df.Target.str.contains(',')].loc[:, ['Target', 'Query']]\n",
    "#not required anymore as those are pairs in the graph file as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#no add a comparision column to po_df and _tmp_df\n",
    "po_df['comp'] = po_df['Query'] + po_df['Target']\n",
    "_tmp_df['comp'] = _tmp_df['Query'] + _tmp_df['Target']\n",
    "#generate a new PO_allele column\n",
    "_tmp_df['PO_allele'] = False\n",
    "#and set it to True\n",
    "_tmp_df.loc[_tmp_df[_tmp_df.comp.isin(po_df.comp.unique())].index, 'PO_allele' ]= True\n",
    "#now drop the comp column again\n",
    "_tmp_df = _tmp_df.drop('comp', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this is changed in version two to account for PO_allele analysis as well\n",
    "_tmp_grouped = _tmp_df[(_tmp_df['t_contig == h_contig_overlap'] == True)\\\n",
    "                      & (_tmp_df['PO_allele'] ==  True)].groupby('Query')\n",
    "\n",
    "#filter on the evalue and than on the BitScore\n",
    "best_hits_t_contig_and_h_contig = _tmp_grouped.apply(lambda g: g[(g['e-value'] == g['e-value'].min())])\n",
    "best_hits_t_contig_and_h_contig = best_hits_t_contig_and_h_contig.reset_index(drop=True).groupby('Query').apply(lambda g: g[(g['BitScore'] == g['BitScore'].max())])\n",
    "\n",
    "out_name = p_genome + '.h_contig_overlap.alleles'\n",
    "\n",
    "best_hits_t_contig_and_h_contig.loc[:, ['Query', 'Target']].to_csv(os.path.join(ALLELE_PATH, out_name), sep='\\t', index=None, header=None)\n",
    "#now save including the filter as well\n",
    "if Qcov_cut_off and PctID_cut_off:\n",
    "    out_name = p_genome + '.h_contig_overlap.Qcov%s.PctID%s.alleles' % (Qcov_cut_off,PctID_cut_off)\n",
    "    best_hits_t_contig_and_h_contig[(best_hits_t_contig_and_h_contig['QCov'] >= Qcov_cut_off) & (best_hits_t_contig_and_h_contig['PctID'] >= PctID_cut_off)]\\\n",
    "    .loc[:, ['Query', 'Target']].to_csv(os.path.join(ALLELE_PATH, out_name), sep='\\t', index=None, header=None)\n",
    "else:\n",
    "    print(\"No filter selected for Qcov and PctID cut-off. If single filter desired set other filter to 1000.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All good please proceed!\n"
     ]
    }
   ],
   "source": [
    "#test if filtering like this works\n",
    "if set(_tmp_df[(_tmp_df['t_contig == h_contig_overlap'] == True)\\\n",
    "                      & (_tmp_df['PO_allele'] ==  True)]['Query'].unique()) == set(best_hits_t_contig_and_h_contig['Query'].unique().tolist()):\n",
    "    print(\"All good please proceed!\")\n",
    "else:\n",
    "    print('The filter threw an error. Not the expected output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now drop everything that was already captured\n",
    "query_ids_to_drop = best_hits_t_contig_and_h_contig['Query'].unique().tolist()\n",
    "target_ids_to_drop = best_hits_t_contig_and_h_contig['Target'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get all queries that are on the respective haplotig but have not been caught before\n",
    "_tmp_groupbed = _tmp_df[(~_tmp_df['Query'].isin(query_ids_to_drop))&\\\n",
    "                        (_tmp_df['q_contig == t_contig'] == True)&\\\n",
    "                        (_tmp_df['PO_allele'] ==  True)].groupby('Query')\n",
    "best_hits_same_contig_no_overlap = _tmp_groupbed.apply(lambda g: g[(g['e-value'] == g['e-value'].min())]) \n",
    "best_hits_same_contig_no_overlap = best_hits_same_contig_no_overlap.reset_index(drop=True).groupby('Query').apply(lambda g: g[(g['BitScore'] == g['BitScore'].max())])\n",
    "out_name = p_genome + '.no_specific_h_contig_overlap.alleles'\n",
    "best_hits_same_contig_no_overlap.loc[:, ['Query', 'Target']].to_csv(os.path.join(ALLELE_PATH, out_name), sep='\\t', index=None, header=None)\n",
    "\n",
    "#now save including the filter as well\n",
    "if Qcov_cut_off and PctID_cut_off:\n",
    "    out_name = p_genome + '.no_specific_h_contig_overlap.Qcov%s.PctID%s.alleles' % (Qcov_cut_off,PctID_cut_off)\n",
    "    best_hits_same_contig_no_overlap[(best_hits_same_contig_no_overlap['QCov'] >= Qcov_cut_off) & (best_hits_same_contig_no_overlap['PctID'] >= PctID_cut_off)]\\\n",
    "    .loc[:, ['Query', 'Target']].to_csv(os.path.join(ALLELE_PATH, out_name), sep='\\t', index=None, header=None)\n",
    "else:\n",
    "    print(\"No filter selected for Qcov and PctID cut-off. If single filter desired set other filter to 1000.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All good please proceed!\n"
     ]
    }
   ],
   "source": [
    "#test if filtering like this works\n",
    "if set(_tmp_df[(~_tmp_df['Query'].isin(query_ids_to_drop))& (_tmp_df['q_contig == t_contig'] == True)\\\n",
    "              & (_tmp_df['PO_allele'] ==  True)]['Query'].unique())\\\n",
    "        == set(best_hits_same_contig_no_overlap['Query'].unique().tolist()):\n",
    "    print(\"All good please proceed!\")\n",
    "else:\n",
    "    print('The filter threw an error. Not the expected output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now drop everything that was already captured\n",
    "query_ids_to_drop = query_ids_to_drop + best_hits_same_contig_no_overlap['Query'].unique().tolist()\n",
    "target_ids_to_drop = target_ids_to_drop + best_hits_same_contig_no_overlap['Target'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get all else. Meaning not on the corresponding haplotig but other haplotig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_tmp_groupbed = _tmp_df[(~_tmp_df['Query'].isin(query_ids_to_drop))&\\\n",
    "                        (_tmp_df['q_contig == t_contig'] == False)\\\n",
    "                        & (_tmp_df['Target'] != 'NaN' )&\n",
    "                        (_tmp_df['PO_allele'] ==  True)].groupby('Query')\n",
    "best_hits_different_contig = _tmp_groupbed.apply(lambda g: g[(g['e-value'] == g['e-value'].min()) ])\n",
    "best_hits_different_contig = best_hits_different_contig .reset_index(drop=True).groupby('Query').apply(lambda g: g[(g['BitScore'] == g['BitScore'].max())])\n",
    "out_name = p_genome + '.no_respective_h_contig_overlap.alleles'\n",
    "best_hits_different_contig.loc[:, ['Query', 'Target']].to_csv(os.path.join(ALLELE_PATH, out_name), sep='\\t', index=None, header=None)\n",
    "\n",
    "#now save including the filter as well\n",
    "if Qcov_cut_off and PctID_cut_off:\n",
    "    out_name = p_genome + '.no_respective_h_contig_overlap.Qcov%s.PctID%s.alleles' % (Qcov_cut_off,PctID_cut_off)\n",
    "    best_hits_different_contig[(best_hits_different_contig['QCov'] >= Qcov_cut_off) & (best_hits_different_contig['PctID'] >= PctID_cut_off)]\\\n",
    "    .loc[:, ['Query', 'Target']].to_csv(os.path.join(ALLELE_PATH, out_name), sep='\\t', index=None, header=None)\n",
    "else:\n",
    "    print(\"No filter selected for Qcov and PctID cut-off. If single filter desired set other filter to 1000.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All good please proceed!\n"
     ]
    }
   ],
   "source": [
    "if set(_tmp_df[(~_tmp_df['Query'].isin(query_ids_to_drop))& (_tmp_df['q_contig == t_contig'] == False) &\\\n",
    "               (_tmp_df['Target'] != 'NaN' )\\\n",
    "              &(_tmp_df['PO_allele'] ==  True)]['Query'].unique().tolist())\\\n",
    "        == set(best_hits_different_contig['Query'].unique().tolist()):\n",
    "    print(\"All good please proceed!\")\n",
    "else:\n",
    "    print('The filter threw an error. Not the expected output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now drop everything that was already captured\n",
    "query_ids_to_drop = query_ids_to_drop + best_hits_different_contig['Query'].unique().tolist()\n",
    "target_ids_to_drop = target_ids_to_drop + best_hits_different_contig['Target'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now print out the p_proteins without alleles\n",
    "out_name = p_genome + '.no_alleles'\n",
    "_tmp_df[~_tmp_df['Query'].isin(query_ids_to_drop)].drop_duplicates(subset='Query')['Query'].to_csv(os.path.join(ALLELE_PATH, out_name), sep='\\t', index=None, header=None)\n",
    "\n",
    "#for filtering different query and targets to drop are required to be dropped\n",
    "if Qcov_cut_off and PctID_cut_off:\n",
    "    query_ids_to_drop_filtered = \\\n",
    "    best_hits_t_contig_and_h_contig[(best_hits_t_contig_and_h_contig['QCov'] >= Qcov_cut_off) & (best_hits_t_contig_and_h_contig['PctID']>= PctID_cut_off)]['Query'].unique().tolist() \\\n",
    "    + best_hits_same_contig_no_overlap[(best_hits_same_contig_no_overlap['QCov'] >= Qcov_cut_off) & (best_hits_same_contig_no_overlap['PctID'] >= PctID_cut_off)]['Query'].unique().tolist()\\\n",
    "    + best_hits_different_contig[(best_hits_different_contig['QCov'] >= Qcov_cut_off) & (best_hits_different_contig['PctID'] >= PctID_cut_off)]['Query'].unique().tolist()\n",
    "    \n",
    "    target_ids_to_drop_filtered = \\\n",
    "    best_hits_t_contig_and_h_contig[(best_hits_t_contig_and_h_contig['QCov'] >= Qcov_cut_off) & (best_hits_t_contig_and_h_contig['PctID']>= PctID_cut_off)]['Target'].unique().tolist()\\\n",
    "    + best_hits_same_contig_no_overlap[(best_hits_same_contig_no_overlap['QCov'] >= Qcov_cut_off) & (best_hits_same_contig_no_overlap['PctID'] >= PctID_cut_off)]['Target'].unique().tolist() \\\n",
    "    + best_hits_different_contig[(best_hits_different_contig['QCov'] >= Qcov_cut_off) & (best_hits_different_contig['PctID'] >= PctID_cut_off)]['Target'].unique().tolist()\n",
    "    out_name = p_genome + '.Qcov%s.PctID%s.no_alleles' % (Qcov_cut_off,PctID_cut_off)\n",
    "    #save the dataframe\n",
    "    _tmp_df[~_tmp_df['Query'].isin(query_ids_to_drop_filtered)].drop_duplicates(subset='Query')['Query'].to_csv(os.path.join(ALLELE_PATH, out_name), sep='\\t', index=None, header=None)    \n",
    "else:\n",
    "    print(\"No filter selected for Qcov and PctID cut-off. If single filter desired set other filter to 1000.\")                                                                                                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save back the dataframe with '.analyzed' added to the key\n",
    "blast_out_dict[_key+'.analyzed'] = _tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pull out the h on p blast dataframe\n",
    "_key = [x for x in blast_out_dict.keys() if x.startswith(h_genome) and x.split('.')[-2] == 'blastp' and x.endswith('outfmt6')][0]\n",
    "_tmp_df = blast_out_dict[_key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pull out all h_contigs without alleles\n",
    "_tmp_df_no_alleles = _tmp_df[~_tmp_df['Query'].isin(target_ids_to_drop)]\n",
    "out_name = h_genome + '.no_alleles'\n",
    "_tmp_df_no_alleles.drop_duplicates(subset='Query')['Query'].to_csv(os.path.join(ALLELE_PATH, out_name), sep='\\t', index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now pull out all h_proteins that have a blast hit but were left behind with selection \n",
    "#based on proteinortho and best blast hits above. No QCov and PctID filtering\n",
    "_tmp_df_no_alleles_grouped = _tmp_df_no_alleles[_tmp_df_no_alleles[\"Target\"] != 'NaN'].groupby('Query')\n",
    "h_protein_no_alleles = _tmp_df_no_alleles_grouped.apply(lambda g: g[(g['e-value'] == g['e-value'].min())]) \n",
    "h_protein_no_alleles = h_protein_no_alleles.reset_index(drop=True).groupby('Query').apply(lambda g: g[(g['BitScore'] == g['BitScore'].max())])\n",
    "out_name = h_genome + '.best_p_hits.no_alleles'\n",
    "h_protein_no_alleles.loc[:, ['Query', 'Target']].to_csv(os.path.join(ALLELE_PATH, out_name), sep='\\t', index=None, header=None)\n",
    "#write done the hits with no blast hit at all. Meaning blasting h on p gave no results\n",
    "out_name = h_genome + '.no_p_hits.no_alleles'\n",
    "_tmp_df_no_alleles[_tmp_df_no_alleles[\"Target\"] == 'NaN']['Query'].to_csv(os.path.join(ALLELE_PATH, out_name), sep='\\t', index=None, header=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now pull out all h_proteins that have a blast hit but were left behind with selection of best blast hits above. With QCov and PctID filtering.\n",
    "if Qcov_cut_off and PctID_cut_off:\n",
    "#pull out all h proteins without alleles when filtering was applied\n",
    "    _tmp_df_no_alleles_filtered = _tmp_df[~_tmp_df['Query'].isin(target_ids_to_drop_filtered)]\n",
    "    out_name = h_genome + '.Qcov%s.PctID%s.no_alleles' % (Qcov_cut_off,PctID_cut_off)\n",
    "    _tmp_df_no_alleles_filtered.drop_duplicates(subset='Query')['Query'].to_csv(os.path.join(ALLELE_PATH, out_name), sep='\\t', index=None, header=None)\n",
    "\n",
    "#pull out all the h proteins with blast hit when filtering was applied and filter those as well.\n",
    "    #first get ride of all NAs in future version maybe convert QCov and PctID to floats or ints so this is not neccessary anymore\n",
    "    _tmp_df_no_alleles_filtered_no_NA = _tmp_df_no_alleles_filtered[(_tmp_df_no_alleles_filtered[\"Target\"] != 'NaN')]\n",
    "    _tmp_df_no_alleles_filtered_grouped = \\\n",
    "        _tmp_df_no_alleles_filtered_no_NA[(_tmp_df_no_alleles_filtered_no_NA['QCov'] >= Qcov_cut_off) &\\\n",
    "                                    (_tmp_df_no_alleles_filtered_no_NA['PctID'] >= PctID_cut_off)].groupby('Query') \n",
    "\n",
    "    h_protein_no_alleles_filtered = _tmp_df_no_alleles_filtered_grouped.apply(lambda g: g[(g['e-value'] == g['e-value'].min())]) \n",
    "    h_protein_no_alleles_filtered = h_protein_no_alleles_filtered.reset_index(drop=True).groupby('Query').apply(lambda g: g[(g['BitScore'] == g['BitScore'].max())])\n",
    "    out_name = h_genome + '.best_p_hits.Qcov%s.PctID%s.no_alleles' % (Qcov_cut_off,PctID_cut_off)\n",
    "    h_protein_no_alleles_filtered.loc[:, ['Query', 'Target']].to_csv(os.path.join(ALLELE_PATH, out_name), sep='\\t', index=None, header=None)\n",
    "    target_ids_to_drop_filtered = target_ids_to_drop_filtered + h_protein_no_alleles_filtered['Query'].unique().tolist()\n",
    "    out_name = h_genome + '.no_p_hits.Qcov%s.PctID%s.no_alleles' % (Qcov_cut_off,PctID_cut_off)\n",
    "    _tmp_df_no_alleles_filtered[~_tmp_df_no_alleles_filtered['Query'].isin(target_ids_to_drop_filtered)].drop_duplicates(subset='Query')['Query']\\\n",
    "    .to_csv(os.path.join(ALLELE_PATH, out_name), sep='\\t', index=None, header=None)\n",
    "else:\n",
    "    print(\"No filter selected for Qcov and PctID cut-off. If single filter desired set other filter to 1000.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write the dataframe again\n",
    "_tmp_df.to_csv(os.path.join(OUT_PATH, _key+'.allele_analysis'), index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Query', 'Target', 'PctID', 'AlnLgth', 'NumMis', 'NumGap', 'StartQuery',\n",
       "       'StopQuery', 'StartTarget', 'StopTarget', 'e-value', 'BitScore',\n",
       "       'QLgth', 'QCov', 'q_contig', 't_contig', 'q_contig == t_contig'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_tmp_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Query', 'Target', 'PctID', 'AlnLgth', 'NumMis', 'NumGap', 'StartQuery',\n",
       "       'StopQuery', 'StartTarget', 'StopTarget', 'e-value', 'BitScore',\n",
       "       'QLgth', 'QCov', 'q_contig', 't_contig', 'q_contig == t_contig',\n",
       "       'p_protein', 'h_contig_overlap', 't_contig == h_contig_overlap',\n",
       "       'PO_allele'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#might be good to write these analyzed dataframes out as well to make life a bit easier\n",
    "blast_out_dict['Pst_104E_v12_p_ctg.Pst_104E_v12_h_ctg.0.001.blastp.outfmt6.analyzed'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
